import { GoogleGenerativeAI } from "@google/generative-ai"
import { NextResponse } from "next/server"
import { SYSTEM_CONTEXT } from "@/lib/system-context"
import { formatContentKnowledgeForGemini } from "@/lib/content-knowledge-base"

interface Message {
  role: "user" | "assistant"
  content: string
}

// Get Gemini client (primary or fallback)
function getGeminiClient(useFallback: boolean = false) {
  const apiKey = useFallback ? process.env.GEMINI_API_KEY_2 : process.env.GEMINI_API_KEY
  const keyType = useFallback ? 'FALLBACK' : 'PRIMARY'
  const envVar = useFallback ? 'GEMINI_API_KEY_2' : 'GEMINI_API_KEY'
  
  if (!apiKey || apiKey === 'INSERT_YOUR_SECOND_GEMINI_API_KEY_HERE' || apiKey === 'INSERT_YOUR_GEMINI_API_KEY_HERE') {
    console.error(`‚ùå ${keyType} Gemini API key not configured (${envVar})`)
    return null
  }
  
  console.log(`‚úÖ ${keyType} Gemini API key configured (${envVar}: ${apiKey.substring(0, 8)}...${apiKey.substring(apiKey.length - 4)})`)
  const genAI = new GoogleGenerativeAI(apiKey)
  return genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" })
}

// Helper to check if error is rate limit
function isRateLimitError(error: any): boolean {
  if (!error) {
    console.log('üîç isRateLimitError: No error object')
    return false
  }
  
  const errorString = JSON.stringify(error).toLowerCase()
  const message = error?.message?.toLowerCase() || ''
  const errorResponse = error?.response?.data?.error?.message?.toLowerCase() || ''
  
  const isRateLimit = (
    error?.status === 429 ||
    error?.statusCode === 429 ||
    error?.response?.status === 429 ||
    message.includes('429') ||
    message.includes('rate limit') ||
    message.includes('too many requests') ||
    message.includes('quota') ||
    message.includes('resource exhausted') ||
    errorString.includes('429') ||
    errorString.includes('resource_exhausted') ||
    errorString.includes('rate limit') ||
    errorResponse.includes('quota') ||
    errorResponse.includes('rate limit')
  )
  
  console.log(`üîç isRateLimitError result: ${isRateLimit}`)
  console.log(`   Status: ${error?.status || error?.statusCode || error?.response?.status}`)
  console.log(`   Message snippet: ${message.substring(0, 100)}`)
  
  return isRateLimit
}

export async function POST(request: Request) {
  try {
    const { prompt, context, conversationHistory = [], mode = "tutor", query, userApiKey } = await request.json()

    // Handle Br√∫jula mode early (uses 'query' instead of 'prompt')
    if (mode === "brujula") {
      console.log("üß≠ [BR√öJULA MODE] Starting request")
      console.log(`üìù Query: "${query?.substring(0, 100)}${query?.length > 100 ? '...' : ''}"`)
      
      // If user provided their own API key, use it directly (third-level fallback)
      if (userApiKey && userApiKey.trim()) {
        console.log("üîë [BR√öJULA] User provided their own API key, using it directly")
        try {
          const genAI = new GoogleGenerativeAI(userApiKey.trim())
          const userModel = genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" })
          const result = await handleBrujulaMode(query, userModel, "user-provided-key", false)
          console.log(`‚úÖ [BR√öJULA] User API key success`)
          return result
        } catch (userKeyError: any) {
          console.error("‚ùå [BR√öJULA] User API key failed:", userKeyError?.message)
          // If user's key fails, return specific error
          return NextResponse.json({
            error: "La API key que proporcionaste no es v√°lida o ha alcanzado su l√≠mite. Verific√° que sea correcta.",
            success: false,
            errorType: 'invalid_user_key'
          }, { status: 400 })
        }
      }
      
      const primaryModel = getGeminiClient(false)
      const fallbackModel = getGeminiClient(true)
      
      // If primary Gemini is not configured, try fallback
      if (!primaryModel) {
        console.log("‚ö†Ô∏è [BR√öJULA] Primary API not configured, attempting fallback...")
        if (fallbackModel) {
          console.log("üîÑ [BR√öJULA] Using FALLBACK API")
          return await handleBrujulaMode(query, fallbackModel, "gemini-secondary", true)
        }
        // No AI provider available
        console.error("‚ùå [BR√öJULA] No API keys configured")
        return NextResponse.json(
          { error: "No hay ning√∫n proveedor de IA configurado. Por favor, configur√° GEMINI_API_KEY o GEMINI_API_KEY_2 en el archivo .env.local", success: false },
          { status: 500 }
        )
      }
      
      // Try primary Gemini first, fallback to secondary if rate limited
      const startTime = Date.now()
      try {
        console.log("üöÄ [BR√öJULA] Attempting PRIMARY API...")
        const result = await handleBrujulaMode(query, primaryModel, "gemini", false)
        const duration = Date.now() - startTime
        console.log(`‚úÖ [BR√öJULA] PRIMARY API success (${duration}ms)`)
        return result
      } catch (error: any) {
        const duration = Date.now() - startTime
        console.log(`‚ö†Ô∏è [BR√öJULA] PRIMARY API failed (${duration}ms)`)
        console.error("Error details:", {
          status: error?.status,
          statusCode: error?.statusCode,
          message: error?.message,
          type: error?.constructor?.name
        })
        
        // Check if it's a rate limit error
        if (isRateLimitError(error)) {
          console.log("üîÑ [BR√öJULA] Rate limit detected, attempting FALLBACK API...")
          if (fallbackModel) {
            const fallbackStartTime = Date.now()
            try {
              const result = await handleBrujulaMode(query, fallbackModel, "gemini-secondary", true)
              const fallbackDuration = Date.now() - fallbackStartTime
              console.log(`‚úÖ [BR√öJULA] FALLBACK API success (${fallbackDuration}ms)`)
              return result
            } catch (fallbackError: any) {
              const fallbackDuration = Date.now() - fallbackStartTime
              console.error(`‚ùå [BR√öJULA] FALLBACK API also failed (${fallbackDuration}ms)`, fallbackError)
              // Both APIs failed - return user-friendly error
              return NextResponse.json({
                error: "El servicio de b√∫squeda est√° temporalmente sobrecargado. Por favor, intent√° de nuevo en unos segundos.",
                success: false,
                errorType: 'rate_limit'
              }, { status: 429 })
            }
          }
          // No fallback available
          console.error("‚ùå [BR√öJULA] No fallback configured, returning rate limit error")
          return NextResponse.json({
            error: "El servicio de b√∫squeda est√° temporalmente sobrecargado. Por favor, intent√° de nuevo en unos segundos.",
            success: false,
            errorType: 'rate_limit'
          }, { status: 429 })
        }
        // Not a rate limit error, re-throw
        throw error
      }
    }

    // For Tutor mode, prompt is required
    if (!prompt) {
      return NextResponse.json(
        { error: "El prompt es requerido" },
        { status: 400 }
      )
    }

    console.log("üéì [TUTOR MODE] Starting request")
    console.log(`üìù Prompt: "${prompt?.substring(0, 100)}${prompt?.length > 100 ? '...' : ''}"`)
    console.log(`üìö Context length: ${context?.length || 0} chars`)
    console.log(`üí¨ Conversation history: ${conversationHistory?.length || 0} messages`)
    
    // If user provided their own API key, use it directly (third-level fallback)
    if (userApiKey && userApiKey.trim()) {
      console.log("üîë [TUTOR] User provided their own API key, using it directly")
      try {
        const genAI = new GoogleGenerativeAI(userApiKey.trim())
        const userModel = genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" })
        const result = await handleTutorMode(userModel, prompt, context, conversationHistory, "user-provided-key", false)
        console.log(`‚úÖ [TUTOR] User API key success`)
        return result
      } catch (userKeyError: any) {
        console.error("‚ùå [TUTOR] User API key failed:", userKeyError?.message)
        return NextResponse.json({
          error: "La API key que proporcionaste no es v√°lida o ha alcanzado su l√≠mite. Verific√° que sea correcta.",
          success: false,
          errorType: 'invalid_user_key'
        }, { status: 400 })
      }
    }
    
    const primaryModel = getGeminiClient(false)
    const fallbackModel = getGeminiClient(true)
    
    // If primary Gemini is not configured, try fallback
    if (!primaryModel) {
      console.log("‚ö†Ô∏è [TUTOR] Primary API not configured, attempting fallback...")
      if (fallbackModel) {
        console.log("üîÑ [TUTOR] Using FALLBACK API")
        return await handleTutorMode(fallbackModel, prompt, context, conversationHistory, "gemini-secondary", true)
      }
      // No AI provider available
      console.error("‚ùå [TUTOR] No API keys configured")
      return NextResponse.json(
        { error: "No hay ning√∫n proveedor de IA configurado. Por favor, configur√° GEMINI_API_KEY o GEMINI_API_KEY_2 en el archivo .env.local", success: false },
        { status: 500 }
      )
    }

    // Try primary Gemini first for Tutor mode, fallback to secondary if rate limited
    const startTime = Date.now()
    try {
      console.log("üöÄ [TUTOR] Attempting PRIMARY API...")
      const result = await handleTutorMode(primaryModel, prompt, context, conversationHistory, "gemini", false)
      const duration = Date.now() - startTime
      console.log(`‚úÖ [TUTOR] PRIMARY API success (${duration}ms)`)
      return result
    } catch (error: any) {
      const duration = Date.now() - startTime
      console.log(`‚ö†Ô∏è [TUTOR] PRIMARY API failed (${duration}ms)`)
      console.error("Error details:", {
        status: error?.status,
        statusCode: error?.statusCode,
        message: error?.message,
        type: error?.constructor?.name
      })
      
      // Check if it's a rate limit error
      if (isRateLimitError(error)) {
        console.log("üîÑ [TUTOR] Rate limit detected, attempting FALLBACK API...")
        if (fallbackModel) {
          const fallbackStartTime = Date.now()
          try {
            const result = await handleTutorMode(fallbackModel, prompt, context, conversationHistory, "gemini-secondary", true)
            const fallbackDuration = Date.now() - fallbackStartTime
            console.log(`‚úÖ [TUTOR] FALLBACK API success (${fallbackDuration}ms)`)
            return result
          } catch (fallbackError: any) {
            const fallbackDuration = Date.now() - fallbackStartTime
            console.error(`‚ùå [TUTOR] FALLBACK API also failed (${fallbackDuration}ms)`, fallbackError)
            // Both APIs failed - return user-friendly error
            return NextResponse.json({
              error: "El servicio de IA est√° temporalmente sobrecargado. Por favor, intent√° de nuevo en unos segundos.",
              success: false,
              errorType: 'rate_limit'
            }, { status: 429 })
          }
        }
        // No fallback available
        console.error("‚ùå [TUTOR] No fallback configured, returning rate limit error")
        return NextResponse.json({
          error: "El servicio de IA est√° temporalmente sobrecargado. Por favor, intent√° de nuevo en unos segundos.",
          success: false,
          errorType: 'rate_limit'
        }, { status: 429 })
      }
      // Not a rate limit error, re-throw
      throw error
    }

  } catch (error) {
    console.error("Error en API de Gemini:", error)
    
    // Proporcionar m√°s detalles del error
    let errorMessage = "Error al procesar la solicitud"
    if (error instanceof Error) {
      errorMessage = error.message
      console.error("Detalles del error:", {
        message: error.message,
        stack: error.stack,
        name: error.name
      })
    }
    
    return NextResponse.json(
      { 
        error: errorMessage,
        success: false 
      },
      { status: 500 }
    )
  }
}

// Handle Tutor mode with Gemini
async function handleTutorMode(
  model: any,
  prompt: string,
  context: string,
  conversationHistory: Message[],
  provider: string,
  usedFallback: boolean = false
) {
  const apiType = usedFallback ? 'FALLBACK' : 'PRIMARY'
  console.log(`‚öôÔ∏è  [TUTOR] Processing with ${apiType} API (${provider})`)
  // Usar el contexto del sistema desde CONTEXT_LLM.md (for Tutor mode)
    const systemContext = `CONTEXTO DEL SISTEMA:

${SYSTEM_CONTEXT}

---

INSTRUCCIONES ADICIONALES:
Cuando el usuario pregunte sobre "flujo de vibecoding" o "integrar en vibecoding", refi√©rete siempre al proceso de programar con asistencia de IA usando las herramientas mencionadas (Cursor, Claude, v0, Lovable, etc.), NO a usar herramientas no-code/low-code.`

    // Construir el historial de conversaci√≥n para Gemini
    let conversationContext = ""
    if (conversationHistory.length > 0) {
      conversationContext = "\n\nHISTORIAL DE LA CONVERSACI√ìN:\n"
      conversationHistory.forEach((msg: Message) => {
        conversationContext += `\n${msg.role === "user" ? "Usuario" : "Asistente"}: ${msg.content}\n`
      })
      conversationContext += "\n---\n"
    }

    // Verificar si el contexto es solo un nombre de t√©rmino (muy corto)
    const isMinimalContext = context && context.trim().length < 100

    const fullPrompt = context
      ? `${systemContext}

---

${isMinimalContext 
  ? `T√©rmino del glosario de desarrollo: ${context.replace(/\*\*/g, "").trim()}`
  : `Contexto del glosario de desarrollo:\n${context}`}
${conversationContext}

Solicitud actual del usuario: ${prompt}

---

INSTRUCCIONES DE RESPUESTA:
Responde de manera clara y did√°ctica, usando lenguaje accesible para personas que est√°n aprendiendo a programar con IA (vibecoding). Si es relevante, incluye ejemplos pr√°cticos y explica c√≥mo aplicar el concepto en un flujo de desarrollo asistido por IA.

${isMinimalContext ? "NOTA: El usuario est√° preguntando sobre un t√©rmino espec√≠fico del glosario. Proporciona una explicaci√≥n completa bas√°ndote en tu conocimiento del t√©rmino." : ""}

${conversationHistory.length > 0 ? "IMPORTANTE: Tienes contexto de la conversaci√≥n anterior. Usa esa informaci√≥n para dar respuestas m√°s espec√≠ficas y relevantes. Puedes hacer referencia a respuestas anteriores si es apropiado." : ""}

FORMATO:
- Usa **negrita** para t√©rminos importantes
- Usa *it√°lica* para √©nfasis
- Usa listas con - o n√∫meros cuando enumeres cosas
- Usa \`c√≥digo\` para comandos o c√≥digo
- Usa bloques de c√≥digo con \`\`\` para ejemplos de c√≥digo m√°s largos
- Usa ### para subt√≠tulos si es necesario

Mant√©n la respuesta concisa pero completa.`
      : `${systemContext}
${conversationContext}

Solicitud actual del usuario: ${prompt}

---

Responde de manera clara y did√°ctica para personas aprendiendo a programar con IA.`

    let text
    try {
      const result = await model.generateContent(fullPrompt)
      const response = await result.response
      text = response.text()
    } catch (apiError: any) {
      console.error(`üí• [TUTOR] API call error:`, {
        name: apiError?.name,
        message: apiError?.message,
        status: apiError?.status,
        statusCode: apiError?.statusCode
      })
      throw apiError // Re-throw to be caught by outer try-catch
    }
    
    console.log(`üì§ [TUTOR] Returning response (${text.length} chars)`)

    return NextResponse.json({ 
      response: text,
      success: true,
      provider,
      fallbackUsed: usedFallback
    })
}

// Handle Br√∫jula mode - AI-powered navigation
async function handleBrujulaMode(query: string, model: any, provider: string, usedFallback: boolean = false) {
  const apiType = usedFallback ? 'FALLBACK' : 'PRIMARY'
  console.log(`‚öôÔ∏è  [BR√öJULA] Processing with ${apiType} API (${provider})`)
  
  if (!query || query.trim().length === 0) {
    return NextResponse.json(
      { error: "La consulta es requerida", success: false },
      { status: 400 }
    )
  }

  const contentKnowledge = await formatContentKnowledgeForGemini()
  console.log(`üìö [BR√öJULA] Content knowledge loaded (${contentKnowledge.length} chars)`)

    const brujulaPrompt = `${contentKnowledge}

---

CONSULTA DEL USUARIO: "${query}"

---

INSTRUCCIONES:
Eres un asistente emp√°tico que ayuda a vibecoders (personas aprendiendo a programar con IA) a encontrar TODO el contenido que necesitan para tener √©xito.

MENTALIDAD CLAVE:
- Los vibecoders son principiantes que no saben lo que no saben
- Si preguntan por una herramienta, probablemente necesitan conocer TODAS las herramientas relacionadas
- Si tienen un problema, necesitan la cadena completa de conocimiento para resolverlo
- Piensa en el "journey" completo del usuario, no solo en la respuesta literal

EJEMPLOS DE PENSAMIENTO EMP√ÅTICO:
- Pregunta: "¬øQu√© es una consola?" ‚Üí Necesita: Terminal, comandos b√°sicos, Y la gu√≠a de devtools (porque va a encontrar errores ah√≠)
- Pregunta: "C√≥mo uso Cursor?" ‚Üí Necesita: Gu√≠a de Cursor, Terminal (lo va a usar), DevTools (va a debuggear), Git (va a versionar)
- Pregunta: "C√≥mo hago un buen prompt?" ‚Üí Necesita: Heur√≠sticas (OBLIGATORIO), glosario de IA (temperatura, contexto, etc), gu√≠as de vibecoding
- Pregunta: "C√≥mo usar bien la IA?" ‚Üí Necesita: Heur√≠sticas (OBLIGATORIO - es la p√°gina dedicada a esto), conceptos de IA, gu√≠as de vibecoding
- Pregunta: "D√≥nde veo errores?" ‚Üí Necesita: DevTools, Terminal, Y c√≥mo copiar errores para v0/Claude

REGLA ESPECIAL: Si la pregunta es sobre "usar IA", "mejores prompts", "comunicarse con IA", "instrucciones a la IA" o similar, la p√°gina de Heur√≠sticas y Buenas Pr√°cticas es OBLIGATORIA como primer link.

REGLA DE ORO: Incluye 3-5 links que cubran el objetivo impl√≠cito completo, no solo la pregunta literal.

1. Analiza la consulta y detecta:
   - ¬øQu√© quiere hacer el usuario? (objetivo expl√≠cito)
   - ¬øQu√© va a necesitar para lograrlo? (objetivo impl√≠cito)
   - ¬øQu√© herramientas/conocimientos complementarios son necesarios?

2. Responde en formato JSON estrictamente con esta estructura:
{
  "answer": "Respuesta amigable y clara explicando qu√© contenido le puede servir al usuario (2-3 oraciones m√°ximo). Usa un tono cercano y did√°ctico.",
  "links": [
    {
      "title": "T√≠tulo del contenido",
      "url": "/ruta/completa#hash-si-aplica",
      "description": "Breve descripci√≥n de por qu√© este link es relevante"
    }
  ],
  "fallback": false
}

3. REGLAS IMPORTANTES:
   - El campo "answer" debe ser texto plano, SIN markdown ni formato especial
   - Incluye 3-5 links que cubran el journey completo del usuario
   - Prioriza gu√≠as y p√°ginas de contenido sobre t√©rminos individuales cuando sea apropiado
   - Las URLs deben ser exactas seg√∫n el mapa de contenido
   - Si es un t√©rmino de glosario, la URL debe incluir el hash (ej: /dashboard/glossary/development#git)
   - Si NO hay contenido relevante en el mapa, usa "fallback": true y sugiere alternativas (ChatGPT, grupo WhatsApp)
   - S√© conciso pero completo en la respuesta

4. EJEMPLOS DE RESPUESTAS:

Ejemplo 1 - Usuario pregunta: "d√≥nde veo los errores para copiarlos a v0?"
{
  "answer": "Para ver y copiar errores, necesit√°s familiarizarte con las DevTools del navegador (F12) y la Terminal. Las DevTools te muestran errores del frontend, y la Terminal te muestra errores del servidor. Ambas son esenciales para vibecoding.",
  "links": [
    {
      "title": "DevTools",
      "url": "/dashboard/glossary/development#devtools",
      "description": "Herramientas del navegador para inspeccionar errores del frontend"
    },
    {
      "title": "Terminal / Command Line",
      "url": "/dashboard/glossary/development#terminal",
      "description": "Para ver errores del servidor y ejecutar comandos"
    },
    {
      "title": "Gu√≠a R√°pida de Vibecoding",
      "url": "/dashboard/vibecoding-guide",
      "description": "Proceso completo de desarrollo incluyendo debugging"
    }
  ],
  "fallback": false
}

Ejemplo 2 - Usuario pregunta: "estoy perdido, c√≥mo uso cursor?"
{
  "answer": "Tranquilo, es normal sentirse perdido al principio. Te recomendamos empezar por la gu√≠a de Cursor, pero tambi√©n vas a necesitar entender la Terminal (para correr comandos), DevTools (para ver tu app), y el flujo completo de vibecoding. Todo est√° conectado.",
  "links": [
    {
      "title": "Introducci√≥n B√°sica a Cursor",
      "url": "/dashboard/cursor-intro",
      "description": "Tutorial b√°sico de c√≥mo usar Cursor IDE desde cero"
    },
    {
      "title": "Gu√≠a R√°pida de Vibecoding",
      "url": "/dashboard/vibecoding-guide",
      "description": "El proceso completo de idea a MVP"
    },
    {
      "title": "Terminal / Command Line",
      "url": "/dashboard/glossary/development#terminal",
      "description": "Comandos b√°sicos que vas a usar en Cursor"
    },
    {
      "title": "DevTools",
      "url": "/dashboard/glossary/development#devtools",
      "description": "Para ver tu app y debuggear problemas"
    }
  ],
  "fallback": false
}

Ejemplo 3 - Usuario pregunta: "c√≥mo escribo mejores prompts?" o "c√≥mo usar bien la IA?"
{
  "answer": "Para usar la IA de manera efectiva, lo m√°s importante es seguir las heur√≠sticas y buenas pr√°cticas espec√≠ficas para comunicarte con IA. Esta es la gu√≠a principal. Tambi√©n te va a servir entender conceptos clave como contexto, temperatura, y c√≥mo estructurar prompts efectivos.",
  "links": [
    {
      "title": "Heur√≠sticas y Buenas Pr√°cticas",
      "url": "/dashboard/heuristics",
      "description": "Gu√≠a completa de c√≥mo usar la IA efectivamente y escribir mejores prompts"
    },
    {
      "title": "Prompt",
      "url": "/dashboard/glossary/ai#prompt",
      "description": "Qu√© es un prompt y c√≥mo funciona"
    },
    {
      "title": "Context / Context Window",
      "url": "/dashboard/glossary/ai#contexto",
      "description": "Entender el contexto para prompts m√°s efectivos"
    },
    {
      "title": "LLM (Large Language Model)",
      "url": "/dashboard/glossary/ai#llm",
      "description": "C√≥mo funcionan los modelos de lenguaje"
    },
    {
      "title": "Gu√≠a R√°pida de Vibecoding",
      "url": "/dashboard/vibecoding-guide",
      "description": "Aplicar buenas pr√°cticas en el flujo completo de desarrollo"
    }
  ],
  "fallback": false
}

Ejemplo 4 - Usuario pregunta algo no cubierto: "c√≥mo funciona blockchain?"
{
  "answer": "No tenemos contenido espec√≠fico sobre blockchain en la plataforma. Para este tema, te recomendamos consultar con ChatGPT, Claude u otro asistente de IA, o preguntar en el grupo de WhatsApp 'Foro' del programa.",
  "links": [],
  "fallback": true
}

AHORA RESPONDE A LA CONSULTA DEL USUARIO en formato JSON puro (sin markdown, sin bloques de c√≥digo, solo el objeto JSON).`

    let text
    try {
      const result = await model.generateContent(brujulaPrompt)
      const response = await result.response
      text = response.text()
    } catch (apiError: any) {
      console.error(`üí• [BR√öJULA] API call error:`, {
        name: apiError?.name,
        message: apiError?.message,
        status: apiError?.status,
        statusCode: apiError?.statusCode
      })
      throw apiError // Re-throw to be caught by outer try-catch
    }

    // Clean up response - remove markdown code blocks if present
    text = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim()

    // Parse JSON response
    let brujulaResponse
    try {
      brujulaResponse = JSON.parse(text)
      console.log(`‚ú® [BR√öJULA] Successfully parsed response with ${brujulaResponse?.links?.length || 0} links`)
    } catch (parseError) {
      console.error("‚ùå [BR√öJULA] Failed to parse Gemini JSON response:", text?.substring(0, 200))
      return NextResponse.json({
        error: "Error al procesar la respuesta de b√∫squeda",
        success: false 
      }, { status: 500 })
    }

  console.log(`üì§ [BR√öJULA] Returning response`)
  return NextResponse.json({
    brujulaResponse,
    success: true,
    provider,
    fallbackUsed: usedFallback
  })
}

