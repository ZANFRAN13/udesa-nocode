import { GoogleGenerativeAI } from "@google/generative-ai"
import { NextResponse } from "next/server"
import { SYSTEM_CONTEXT } from "@/lib/system-context"
import { formatContentKnowledgeForGemini } from "@/lib/content-knowledge-base"

interface Message {
  role: "user" | "assistant"
  content: string
}

// Get Gemini client (primary or fallback)
function getGeminiClient(useFallback: boolean = false) {
  const apiKey = useFallback ? process.env.GEMINI_API_KEY_2 : process.env.GEMINI_API_KEY
  if (!apiKey) return null
  
  const genAI = new GoogleGenerativeAI(apiKey)
  return genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" })
}

export async function POST(request: Request) {
  try {
    const { prompt, context, conversationHistory = [], mode = "tutor", query } = await request.json()

    // Handle Br√∫jula mode early (uses 'query' instead of 'prompt')
    if (mode === "brujula") {
      const primaryModel = getGeminiClient(false)
      const fallbackModel = getGeminiClient(true)
      
      // If primary Gemini is not configured, try fallback
      if (!primaryModel) {
        console.log("‚ö†Ô∏è Primary Gemini API key not found, using secondary key...")
        if (fallbackModel) {
          return await handleBrujulaMode(query, fallbackModel, "gemini-secondary")
        }
        // No AI provider available
        return NextResponse.json(
          { error: "No hay ning√∫n proveedor de IA configurado. Por favor, configur√° GEMINI_API_KEY o GEMINI_API_KEY_2 en el archivo .env.local" },
          { status: 500 }
        )
      }
      
      // Try primary Gemini first, fallback to secondary if rate limited
      try {
        return await handleBrujulaMode(query, primaryModel, "gemini")
      } catch (error: any) {
        // Check if it's a rate limit error
        if (error?.status === 429 || error?.message?.includes('429') || error?.message?.includes('Too Many Requests')) {
          console.log("üîÑ Primary Gemini rate limited, falling back to secondary key...")
          if (fallbackModel) {
            return await handleBrujulaMode(query, fallbackModel, "gemini-secondary")
          }
          // If no fallback available, return the rate limit error
          throw error
        }
        throw error
      }
    }

    // For Tutor mode, prompt is required
    if (!prompt) {
      return NextResponse.json(
        { error: "El prompt es requerido" },
        { status: 400 }
      )
    }

    const primaryModel = getGeminiClient(false)
    const fallbackModel = getGeminiClient(true)
    
    // If primary Gemini is not configured, try fallback
    if (!primaryModel) {
      console.log("‚ö†Ô∏è Primary Gemini API key not found, using secondary key...")
      if (fallbackModel) {
        return await handleTutorMode(fallbackModel, prompt, context, conversationHistory, "gemini-secondary")
      }
      // No AI provider available
      return NextResponse.json(
        { error: "No hay ning√∫n proveedor de IA configurado. Por favor, configur√° GEMINI_API_KEY o GEMINI_API_KEY_2 en el archivo .env.local" },
        { status: 500 }
      )
    }

    // Try primary Gemini first for Tutor mode, fallback to secondary if rate limited
    try {
      return await handleTutorMode(primaryModel, prompt, context, conversationHistory, "gemini")
    } catch (error: any) {
      // Check if it's a rate limit error
      if (error?.status === 429 || error?.message?.includes('429') || error?.message?.includes('Too Many Requests')) {
        console.log("üîÑ Primary Gemini rate limited, falling back to secondary key...")
        if (fallbackModel) {
          return await handleTutorMode(fallbackModel, prompt, context, conversationHistory, "gemini-secondary")
        }
        // If no fallback available, return the rate limit error
        throw error
      }
      throw error
    }

  } catch (error) {
    console.error("Error en API de Gemini:", error)
    
    // Proporcionar m√°s detalles del error
    let errorMessage = "Error al procesar la solicitud"
    if (error instanceof Error) {
      errorMessage = error.message
      console.error("Detalles del error:", {
        message: error.message,
        stack: error.stack,
        name: error.name
      })
    }
    
    return NextResponse.json(
      { 
        error: errorMessage,
        success: false 
      },
      { status: 500 }
    )
  }
}

// Handle Tutor mode with Gemini
async function handleTutorMode(
  model: any,
  prompt: string,
  context: string,
  conversationHistory: Message[],
  provider: string
) {
  // Usar el contexto del sistema desde CONTEXT_LLM.md (for Tutor mode)
    const systemContext = `CONTEXTO DEL SISTEMA:

${SYSTEM_CONTEXT}

---

INSTRUCCIONES ADICIONALES:
Cuando el usuario pregunte sobre "flujo de vibecoding" o "integrar en vibecoding", refi√©rete siempre al proceso de programar con asistencia de IA usando las herramientas mencionadas (Cursor, Claude, v0, Lovable, etc.), NO a usar herramientas no-code/low-code.`

    // Construir el historial de conversaci√≥n para Gemini
    let conversationContext = ""
    if (conversationHistory.length > 0) {
      conversationContext = "\n\nHISTORIAL DE LA CONVERSACI√ìN:\n"
      conversationHistory.forEach((msg: Message) => {
        conversationContext += `\n${msg.role === "user" ? "Usuario" : "Asistente"}: ${msg.content}\n`
      })
      conversationContext += "\n---\n"
    }

    // Verificar si el contexto es solo un nombre de t√©rmino (muy corto)
    const isMinimalContext = context && context.trim().length < 100

    const fullPrompt = context
      ? `${systemContext}

---

${isMinimalContext 
  ? `T√©rmino del glosario de desarrollo: ${context.replace(/\*\*/g, "").trim()}`
  : `Contexto del glosario de desarrollo:\n${context}`}
${conversationContext}

Solicitud actual del usuario: ${prompt}

---

INSTRUCCIONES DE RESPUESTA:
Responde de manera clara y did√°ctica, usando lenguaje accesible para personas que est√°n aprendiendo a programar con IA (vibecoding). Si es relevante, incluye ejemplos pr√°cticos y explica c√≥mo aplicar el concepto en un flujo de desarrollo asistido por IA.

${isMinimalContext ? "NOTA: El usuario est√° preguntando sobre un t√©rmino espec√≠fico del glosario. Proporciona una explicaci√≥n completa bas√°ndote en tu conocimiento del t√©rmino." : ""}

${conversationHistory.length > 0 ? "IMPORTANTE: Tienes contexto de la conversaci√≥n anterior. Usa esa informaci√≥n para dar respuestas m√°s espec√≠ficas y relevantes. Puedes hacer referencia a respuestas anteriores si es apropiado." : ""}

FORMATO:
- Usa **negrita** para t√©rminos importantes
- Usa *it√°lica* para √©nfasis
- Usa listas con - o n√∫meros cuando enumeres cosas
- Usa \`c√≥digo\` para comandos o c√≥digo
- Usa bloques de c√≥digo con \`\`\` para ejemplos de c√≥digo m√°s largos
- Usa ### para subt√≠tulos si es necesario

Mant√©n la respuesta concisa pero completa.`
      : `${systemContext}
${conversationContext}

Solicitud actual del usuario: ${prompt}

---

Responde de manera clara y did√°ctica para personas aprendiendo a programar con IA.`

    const result = await model.generateContent(fullPrompt)
    const response = await result.response
    const text = response.text()

    return NextResponse.json({ 
      response: text,
    success: true,
    provider
  })
}

// Handle Br√∫jula mode - AI-powered navigation
async function handleBrujulaMode(query: string, model: any, provider: string) {
  if (!query || query.trim().length === 0) {
    return NextResponse.json(
      { error: "La consulta es requerida", success: false },
      { status: 400 }
    )
  }

  const contentKnowledge = await formatContentKnowledgeForGemini()

    const brujulaPrompt = `${contentKnowledge}

---

CONSULTA DEL USUARIO: "${query}"

---

INSTRUCCIONES:
Eres un asistente emp√°tico que ayuda a vibecoders (personas aprendiendo a programar con IA) a encontrar TODO el contenido que necesitan para tener √©xito.

MENTALIDAD CLAVE:
- Los vibecoders son principiantes que no saben lo que no saben
- Si preguntan por una herramienta, probablemente necesitan conocer TODAS las herramientas relacionadas
- Si tienen un problema, necesitan la cadena completa de conocimiento para resolverlo
- Piensa en el "journey" completo del usuario, no solo en la respuesta literal

EJEMPLOS DE PENSAMIENTO EMP√ÅTICO:
- Pregunta: "¬øQu√© es una consola?" ‚Üí Necesita: Terminal, comandos b√°sicos, Y la gu√≠a de devtools (porque va a encontrar errores ah√≠)
- Pregunta: "C√≥mo uso Cursor?" ‚Üí Necesita: Gu√≠a de Cursor, Terminal (lo va a usar), DevTools (va a debuggear), Git (va a versionar)
- Pregunta: "C√≥mo hago un buen prompt?" ‚Üí Necesita: Heur√≠sticas (OBLIGATORIO), glosario de IA (temperatura, contexto, etc), gu√≠as de vibecoding
- Pregunta: "C√≥mo usar bien la IA?" ‚Üí Necesita: Heur√≠sticas (OBLIGATORIO - es la p√°gina dedicada a esto), conceptos de IA, gu√≠as de vibecoding
- Pregunta: "D√≥nde veo errores?" ‚Üí Necesita: DevTools, Terminal, Y c√≥mo copiar errores para v0/Claude

REGLA ESPECIAL: Si la pregunta es sobre "usar IA", "mejores prompts", "comunicarse con IA", "instrucciones a la IA" o similar, la p√°gina de Heur√≠sticas y Buenas Pr√°cticas es OBLIGATORIA como primer link.

REGLA DE ORO: Incluye 3-5 links que cubran el objetivo impl√≠cito completo, no solo la pregunta literal.

1. Analiza la consulta y detecta:
   - ¬øQu√© quiere hacer el usuario? (objetivo expl√≠cito)
   - ¬øQu√© va a necesitar para lograrlo? (objetivo impl√≠cito)
   - ¬øQu√© herramientas/conocimientos complementarios son necesarios?

2. Responde en formato JSON estrictamente con esta estructura:
{
  "answer": "Respuesta amigable y clara explicando qu√© contenido le puede servir al usuario (2-3 oraciones m√°ximo). Usa un tono cercano y did√°ctico.",
  "links": [
    {
      "title": "T√≠tulo del contenido",
      "url": "/ruta/completa#hash-si-aplica",
      "description": "Breve descripci√≥n de por qu√© este link es relevante"
    }
  ],
  "fallback": false
}

3. REGLAS IMPORTANTES:
   - El campo "answer" debe ser texto plano, SIN markdown ni formato especial
   - Incluye 3-5 links que cubran el journey completo del usuario
   - Prioriza gu√≠as y p√°ginas de contenido sobre t√©rminos individuales cuando sea apropiado
   - Las URLs deben ser exactas seg√∫n el mapa de contenido
   - Si es un t√©rmino de glosario, la URL debe incluir el hash (ej: /dashboard/glossary/development#git)
   - Si NO hay contenido relevante en el mapa, usa "fallback": true y sugiere alternativas (ChatGPT, grupo WhatsApp)
   - S√© conciso pero completo en la respuesta

4. EJEMPLOS DE RESPUESTAS:

Ejemplo 1 - Usuario pregunta: "d√≥nde veo los errores para copiarlos a v0?"
{
  "answer": "Para ver y copiar errores, necesit√°s familiarizarte con las DevTools del navegador (F12) y la Terminal. Las DevTools te muestran errores del frontend, y la Terminal te muestra errores del servidor. Ambas son esenciales para vibecoding.",
  "links": [
    {
      "title": "DevTools",
      "url": "/dashboard/glossary/development#devtools",
      "description": "Herramientas del navegador para inspeccionar errores del frontend"
    },
    {
      "title": "Terminal / Command Line",
      "url": "/dashboard/glossary/development#terminal",
      "description": "Para ver errores del servidor y ejecutar comandos"
    },
    {
      "title": "Gu√≠a R√°pida de Vibecoding",
      "url": "/dashboard/vibecoding-guide",
      "description": "Proceso completo de desarrollo incluyendo debugging"
    }
  ],
  "fallback": false
}

Ejemplo 2 - Usuario pregunta: "estoy perdido, c√≥mo uso cursor?"
{
  "answer": "Tranquilo, es normal sentirse perdido al principio. Te recomendamos empezar por la gu√≠a de Cursor, pero tambi√©n vas a necesitar entender la Terminal (para correr comandos), DevTools (para ver tu app), y el flujo completo de vibecoding. Todo est√° conectado.",
  "links": [
    {
      "title": "Introducci√≥n B√°sica a Cursor",
      "url": "/dashboard/cursor-intro",
      "description": "Tutorial b√°sico de c√≥mo usar Cursor IDE desde cero"
    },
    {
      "title": "Gu√≠a R√°pida de Vibecoding",
      "url": "/dashboard/vibecoding-guide",
      "description": "El proceso completo de idea a MVP"
    },
    {
      "title": "Terminal / Command Line",
      "url": "/dashboard/glossary/development#terminal",
      "description": "Comandos b√°sicos que vas a usar en Cursor"
    },
    {
      "title": "DevTools",
      "url": "/dashboard/glossary/development#devtools",
      "description": "Para ver tu app y debuggear problemas"
    }
  ],
  "fallback": false
}

Ejemplo 3 - Usuario pregunta: "c√≥mo escribo mejores prompts?" o "c√≥mo usar bien la IA?"
{
  "answer": "Para usar la IA de manera efectiva, lo m√°s importante es seguir las heur√≠sticas y buenas pr√°cticas espec√≠ficas para comunicarte con IA. Esta es la gu√≠a principal. Tambi√©n te va a servir entender conceptos clave como contexto, temperatura, y c√≥mo estructurar prompts efectivos.",
  "links": [
    {
      "title": "Heur√≠sticas y Buenas Pr√°cticas",
      "url": "/dashboard/heuristics",
      "description": "Gu√≠a completa de c√≥mo usar la IA efectivamente y escribir mejores prompts"
    },
    {
      "title": "Prompt",
      "url": "/dashboard/glossary/ai#prompt",
      "description": "Qu√© es un prompt y c√≥mo funciona"
    },
    {
      "title": "Context / Context Window",
      "url": "/dashboard/glossary/ai#contexto",
      "description": "Entender el contexto para prompts m√°s efectivos"
    },
    {
      "title": "LLM (Large Language Model)",
      "url": "/dashboard/glossary/ai#llm",
      "description": "C√≥mo funcionan los modelos de lenguaje"
    },
    {
      "title": "Gu√≠a R√°pida de Vibecoding",
      "url": "/dashboard/vibecoding-guide",
      "description": "Aplicar buenas pr√°cticas en el flujo completo de desarrollo"
    }
  ],
  "fallback": false
}

Ejemplo 4 - Usuario pregunta algo no cubierto: "c√≥mo funciona blockchain?"
{
  "answer": "No tenemos contenido espec√≠fico sobre blockchain en la plataforma. Para este tema, te recomendamos consultar con ChatGPT, Claude u otro asistente de IA, o preguntar en el grupo de WhatsApp 'Foro' del programa.",
  "links": [],
  "fallback": true
}

AHORA RESPONDE A LA CONSULTA DEL USUARIO en formato JSON puro (sin markdown, sin bloques de c√≥digo, solo el objeto JSON).`

    const result = await model.generateContent(brujulaPrompt)
    const response = await result.response
    let text = response.text()

    // Clean up response - remove markdown code blocks if present
    text = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim()

    // Parse JSON response
    let brujulaResponse
    try {
      brujulaResponse = JSON.parse(text)
    } catch (parseError) {
      console.error("Failed to parse Gemini JSON response:", text)
      return NextResponse.json({
        error: "Error al procesar la respuesta de b√∫squeda",
        success: false 
      }, { status: 500 })
    }

  return NextResponse.json({
    brujulaResponse,
    success: true,
    provider
  })
}

